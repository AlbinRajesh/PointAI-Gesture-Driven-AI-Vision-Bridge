{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d527e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32133179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp_hand = mp.solutions.hands#Landmarks\n",
    "# mp_draw = mp.solutions.drawing_utils#drawing landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38e8f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = mp_hand.Hands(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d27bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa57c1e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33488916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AR AI Sniper: ACTIVE\n",
      "- Freeze for 3s to trigger AI Analysis\n",
      "- Press 'R' to reset box | 'Q' to Quit\n",
      "\n",
      "[AI] Analyzing capture: ai_cap_1768635002.png...\n",
      "AI Error: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]\n",
      "Lock Released. Resuming tracking...\n",
      "Lock Released. Resuming tracking...\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import mss\n",
    "import mss.tools\n",
    "import ctypes\n",
    "import tkinter as tk\n",
    "import keyboard\n",
    "import time\n",
    "import sys\n",
    "import threading\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import PIL.Image\n",
    "\n",
    "# --- STEP 1: AI CONFIGURATION ---\n",
    "# Replace 'YOUR_API_KEY' with your actual Gemini API Key\n",
    "genai.configure(api_key=\"YOUR_API_KEY\")\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "def ask_ai_about_image(filename):\n",
    "    \"\"\"Sends the captured image to Gemini for analysis.\"\"\"\n",
    "    print(f\"\\n[AI] Analyzing capture: {filename}...\")\n",
    "    try:\n",
    "        img = PIL.Image.open(filename)\n",
    "        # You can change the prompt below to suit your needs\n",
    "        prompt = \"Describe the most important details inside this box in two short sentences.\"\n",
    "        response = model.generate_content([prompt, img])\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"AI ANALYSIS RESULT:\")\n",
    "        print(response.text.strip())\n",
    "        print(\"=\"*50 + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"AI Error: {e}\")\n",
    "\n",
    "# --- STEP 2: DPI ACCURACY ---\n",
    "try:\n",
    "    ctypes.windll.shcore.SetProcessDpiAwareness(1)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# --- STEP 3: OVERLAY UI ---\n",
    "class Overlay:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.overrideredirect(True)\n",
    "        self.root.attributes(\"-topmost\", True, \"-transparentcolor\", \"white\")\n",
    "        self.root.config(bg='white')\n",
    "        self.root.wm_attributes(\"-disabled\", True)\n",
    "        self.canvas = tk.Canvas(self.root, width=self.root.winfo_screenwidth(), \n",
    "                               height=self.root.winfo_screenheight(), \n",
    "                               bg='white', highlightthickness=0)\n",
    "        self.canvas.pack()\n",
    "        self.rect = self.canvas.create_rectangle(0, 0, 0, 0, outline=\"green\", width=3)\n",
    "        self.label = self.canvas.create_text(0, 0, text=\"\", fill=\"green\", font=(\"Arial\", 14, \"bold\"), anchor=\"sw\")\n",
    "        \n",
    "    def update_box(self, x1, y1, x2, y2, state=\"moving\", countdown=\"\", flash_now=False):\n",
    "        try:\n",
    "            self.canvas.coords(self.rect, x1, y1, x2, y2)\n",
    "            self.canvas.coords(self.label, x1, y1 - 5)\n",
    "            self.canvas.itemconfig(self.label, text=countdown)\n",
    "            self.canvas.itemconfig(self.rect, fill=\"white\" if flash_now else \"\")\n",
    "            \n",
    "            color = \"red\" if state == \"locked\" else \"orange\" if state == \"closing\" else \"green\"\n",
    "            self.canvas.itemconfig(self.rect, outline=color)\n",
    "            self.canvas.itemconfig(self.label, fill=color)\n",
    "            self.root.update()\n",
    "        except: pass\n",
    "\n",
    "    def close(self):\n",
    "        try: self.root.destroy()\n",
    "        except: pass\n",
    "\n",
    "overlay = Overlay()\n",
    "sct = mss.mss()\n",
    "main_monitor = sct.monitors[1] if len(sct.monitors) > 1 else sct.monitors[0]\n",
    "\n",
    "# --- STEP 4: COORDINATES & FLAGS ---\n",
    "current_box = [0, 0, 0, 0] \n",
    "capture_requested = False  \n",
    "is_running = True \n",
    "is_locked = False\n",
    "last_move_time = time.time()\n",
    "fist_start_time = None\n",
    "lock_threshold, lock_delay = 20, 3.0\n",
    "\n",
    "def reset_lock():\n",
    "    global is_locked, last_move_time\n",
    "    is_locked = False\n",
    "    last_move_time = time.time()\n",
    "    print(\"Lock Released. Resuming tracking...\")\n",
    "\n",
    "keyboard.add_hotkey('r', reset_lock)\n",
    "keyboard.add_hotkey('q', lambda: globals().update(is_running=False))\n",
    "\n",
    "# --- STEP 5: VISION BRAIN ---\n",
    "screen_w, screen_h = pyautogui.size()\n",
    "video = cv2.VideoCapture(0)\n",
    "hands_detector = mp.solutions.hands.Hands(max_num_hands=1, min_detection_confidence=0.8)\n",
    "\n",
    "p_t_x, p_t_y, p_i_x, p_i_y = 0, 0, 0, 0\n",
    "smooth_factor = 0.15\n",
    "\n",
    "print(\"AR AI Sniper: ACTIVE\")\n",
    "print(\"- Freeze for 3s to trigger AI Analysis\")\n",
    "print(\"- Press 'R' to reset box | 'Q' to Quit\")\n",
    "\n",
    "try:\n",
    "    while is_running:\n",
    "        success, img = video.read()\n",
    "        if not success: break\n",
    "        \n",
    "        img = cv2.flip(img, 1)\n",
    "        result = hands_detector.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        display_text, current_state, flash_effect = \"\", \"moving\", False\n",
    "\n",
    "        if is_locked:\n",
    "            current_state = \"locked\"\n",
    "            display_text = \"AI ANALYSIS SENT - Press 'R' to move\"\n",
    "        else:\n",
    "            if result.multi_hand_landmarks:\n",
    "                hand_lms = result.multi_hand_landmarks[0]\n",
    "                is_fist = all([hand_lms.landmark[i].y > hand_lms.landmark[i-2].y for i in [8, 12, 16, 20]])\n",
    "\n",
    "                if is_fist:\n",
    "                    fist_start_time = fist_start_time or time.time()\n",
    "                    if time.time() - fist_start_time > 2.0: is_running = False\n",
    "                    display_text, current_state = \"EXITING...\", \"closing\"\n",
    "                else:\n",
    "                    fist_start_time = None \n",
    "                    tx, ty = hand_lms.landmark[4].x * screen_w, hand_lms.landmark[4].y * screen_h\n",
    "                    ix, iy = hand_lms.landmark[8].x * screen_w, hand_lms.landmark[8].y * screen_h\n",
    "\n",
    "                    if abs(tx - p_t_x) + abs(ty - p_t_y) > lock_threshold:\n",
    "                        last_move_time = time.time()\n",
    "                    else:\n",
    "                        if time.time() - last_move_time > lock_delay:\n",
    "                            is_locked, flash_effect = True, True\n",
    "                            # Capture and AI Logic\n",
    "                            x1, y1, x2, y2 = current_box\n",
    "                            width, height = x2 - x1, y2 - y1\n",
    "                            if width > 20:\n",
    "                                region = {\"top\": int(y1), \"left\": int(x1), \"width\": int(width), \"height\": int(height)}\n",
    "                                filename = f\"ai_cap_{int(time.time())}.png\"\n",
    "                                mss.tools.to_png(sct.grab(region).rgb, sct.grab(region).size, output=filename)\n",
    "                                # Start AI analysis in background\n",
    "                                threading.Thread(target=ask_ai_about_image, args=(filename,), daemon=True).start()\n",
    "                        else:\n",
    "                            display_text = f\"Analyzing in {max(0, int(lock_delay - (time.time() - last_move_time)) + 1)}s...\"\n",
    "\n",
    "                    p_t_x += (tx - p_t_x) * smooth_factor\n",
    "                    p_t_y += (ty - p_t_y) * smooth_factor\n",
    "                    p_i_x += (ix - p_i_x) * smooth_factor\n",
    "                    p_i_y += (iy - p_i_y) * smooth_factor\n",
    "                    current_box = [int(min(p_t_x, p_i_x)), int(min(p_t_y, p_i_y)), int(max(p_t_x, p_i_x)), int(max(p_t_y, p_i_y))]\n",
    "\n",
    "        overlay.update_box(*current_box, state=current_state, countdown=display_text, flash_now=flash_effect)\n",
    "        time.sleep(0.01)\n",
    "\n",
    "finally:\n",
    "    video.release()\n",
    "    overlay.close()\n",
    "    keyboard.unhook_all()\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fa7c5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/gemini-flash-latest\n",
      "models/gemini-flash-lite-latest\n",
      "models/gemini-pro-latest\n",
      "models/gemini-2.5-flash-lite\n",
      "models/gemini-2.5-flash-image\n",
      "models/gemini-2.5-flash-preview-09-2025\n",
      "models/gemini-2.5-flash-lite-preview-09-2025\n",
      "models/gemini-3-pro-preview\n",
      "models/gemini-3-flash-preview\n",
      "models/gemini-3-pro-image-preview\n",
      "models/nano-banana-pro-preview\n",
      "models/gemini-robotics-er-1.5-preview\n",
      "models/gemini-2.5-computer-use-preview-10-2025\n",
      "models/deep-research-pro-preview-12-2025\n"
     ]
    }
   ],
   "source": [
    "genai.configure(api_key=\"AIzaSyBcRTBb3IqkSooLBZQPNJi0mjQDm0DVyhI\")\n",
    "model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "for m in genai.list_models():\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print(m.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
