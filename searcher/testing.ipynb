{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d527e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32133179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp_hand = mp.solutions.hands#Landmarks\n",
    "# mp_draw = mp.solutions.drawing_utils#drawing landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38e8f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = mp_hand.Hands(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d27bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff0029f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Ready. Press 'S' to capture the area between your fingers.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import mss\n",
    "import mss.tools\n",
    "import ctypes\n",
    "import time\n",
    "\n",
    "# --- STEP 1: FIX DPI ACCURACY (For High-Res Screens) ---\n",
    "try:\n",
    "    ctypes.windll.shcore.SetProcessDpiAwareness(1)\n",
    "except Exception:\n",
    "    ctypes.windll.user32.SetProcessDPIAware()\n",
    "\n",
    "# --- STEP 2: SETUP ---\n",
    "screen_w, screen_h = pyautogui.size()\n",
    "sct = mss.mss()\n",
    "# Get primary monitor info for coordinate offsets\n",
    "main_monitor = sct.monitors[1]\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "mp_hand = mp.solutions.hands\n",
    "data = mp_hand.Hands(max_num_hands=1, min_detection_confidence=0.8)\n",
    "\n",
    "# Smoothing Variables\n",
    "p_t_x, p_t_y, p_i_x, p_i_y = 0, 0, 0, 0\n",
    "smooth_factor = 0.2\n",
    "\n",
    "print(\"System Ready. Press 'S' to capture the area between your fingers.\")\n",
    "\n",
    "while True:\n",
    "    success, img = video.read()\n",
    "    if not success: break\n",
    "    \n",
    "    img = cv2.flip(img, 1)\n",
    "    h, w, c = img.shape\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    result = data.process(img_rgb)\n",
    "\n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_lms in result.multi_hand_landmarks:\n",
    "            # 1. Get Landmarks\n",
    "            thumb = hand_lms.landmark[4]\n",
    "            index = hand_lms.landmark[8]\n",
    "            \n",
    "            # 2. Apply Smoothing Logic\n",
    "            p_t_x = p_t_x + (thumb.x * screen_w - p_t_x) * smooth_factor\n",
    "            p_t_y = p_t_y + (thumb.y * screen_h - p_t_y) * smooth_factor\n",
    "            p_i_x = p_i_x + (index.x * screen_w - p_i_x) * smooth_factor\n",
    "            p_i_y = p_i_y + (index.y * screen_h - p_i_y) * smooth_factor\n",
    "\n",
    "            # 3. Calculate Box Coordinates (Desktop Scale)\n",
    "            x1, y1 = int(min(p_t_x, p_i_x)), int(min(p_t_y, p_i_y))\n",
    "            x2, y2 = int(max(p_t_x, p_i_x)), int(max(p_t_y, p_i_y))\n",
    "            box_w, box_h = x2 - x1, y2 - y1\n",
    "\n",
    "            # 4. Calculate Box Coordinates (Webcam Preview Scale)\n",
    "            cam_x1, cam_y1 = int((x1/screen_w)*w), int((y1/screen_h)*h)\n",
    "            cam_x2, cam_y2 = int((x2/screen_w)*w), int((y2/screen_h)*h)\n",
    "\n",
    "            # 5. DRAW BOX\n",
    "            cv2.rectangle(img, (cam_x1, cam_y1), (cam_x2, cam_y2), (0, 255, 0), 2)\n",
    "\n",
    "            # 6. TRIGGER: CAPTURE\n",
    "            if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "                if box_w > 20 and box_h > 20:\n",
    "                    # Define capture region relative to Monitor 1\n",
    "                    region = {\n",
    "                        \"top\": main_monitor[\"top\"] + y1,\n",
    "                        \"left\": main_monitor[\"left\"] + x1,\n",
    "                        \"width\": box_w,\n",
    "                        \"height\": box_h\n",
    "                    }\n",
    "                    \n",
    "                    sct_img = sct.grab(region)\n",
    "                    mss.tools.to_png(sct_img.rgb, sct_img.size, output=\"snip.png\")\n",
    "                    print(f\"Captured Snip! Coordinates: {x1, y1} Size: {box_w}x{box_h}\")\n",
    "                    \n",
    "                    # Flash Effect\n",
    "                    cv2.rectangle(img, (cam_x1, cam_y1), (cam_x2, cam_y2), (255, 255, 255), -1)\n",
    "\n",
    "    cv2.imshow(\"AI Sniper - Press 'S' to Capture\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa57c1e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33488916",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
